{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# School Budget Categorization\n",
    "inspired from https://campus.datacamp.com/courses/machine-learning-with-the-experts-school-budgets\n",
    "\n",
    "Approach to a solid (or winning) answer for a competition\n",
    "\n",
    "based on a [www.drivendata.org](https://www.drivendata.org/) competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7,6)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1560, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplemental *</td>\n",
       "      <td>...</td>\n",
       "      <td>Non-Certificated Salaries And Wages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Care and Upkeep of Building Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8291.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I CARRYOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Student Transportation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Shared Services</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>OtherNon-Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12Operating</td>\n",
       "      <td>REPAIR AND MAINTENANCE SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMIN. SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDENT TRANSPORT SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618.29</td>\n",
       "      <td>PUPIL TRANSPORTATION</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>BaseSalary/Compensation</td>\n",
       "      <td>NonPreK</td>\n",
       "      <td>PreK-12Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>49768.82</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>...</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>Instruction And Curriculum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>Title I, Part A Schoolwide Activities Related...</td>\n",
       "      <td>General Operating Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplies and Materials</td>\n",
       "      <td>...</td>\n",
       "      <td>Supplies And Materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other Community Services *</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2304.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I PI+HOMELESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Function          Use          Sharing   Reporting  \\\n",
       "Index                                                                     \n",
       "198                  NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "209    Student Transportation     NO_LABEL  Shared Services  Non-School   \n",
       "750      Teacher Compensation  Instruction  School Reported      School   \n",
       "931                  NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "1524                 NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "\n",
       "      Student_Type Position_Type              Object_Type     Pre_K  \\\n",
       "Index                                                                 \n",
       "198       NO_LABEL      NO_LABEL                 NO_LABEL  NO_LABEL   \n",
       "209       NO_LABEL      NO_LABEL    OtherNon-Compensation  NO_LABEL   \n",
       "750    Unspecified       Teacher  BaseSalary/Compensation   NonPreK   \n",
       "931       NO_LABEL      NO_LABEL                 NO_LABEL  NO_LABEL   \n",
       "1524      NO_LABEL      NO_LABEL                 NO_LABEL  NO_LABEL   \n",
       "\n",
       "       Operating_Status               Object_Description         ...           \\\n",
       "Index                                                            ...            \n",
       "198       Non-Operating                   Supplemental *         ...            \n",
       "209    PreK-12Operating  REPAIR AND MAINTENANCE SERVICES         ...            \n",
       "750    PreK-12Operating     Personal Services - Teachers         ...            \n",
       "931       Non-Operating                 General Supplies         ...            \n",
       "1524      Non-Operating           Supplies and Materials         ...            \n",
       "\n",
       "                    Sub_Object_Description Location_Description  FTE  \\\n",
       "Index                                                                  \n",
       "198    Non-Certificated Salaries And Wages                  NaN  NaN   \n",
       "209                                    NaN      ADMIN. SERVICES  NaN   \n",
       "750                                    NaN                  NaN  1.0   \n",
       "931                       General Supplies                  NaN  NaN   \n",
       "1524                Supplies And Materials                  NaN  NaN   \n",
       "\n",
       "                       Function_Description      Facility_or_Department  \\\n",
       "Index                                                                     \n",
       "198    Care and Upkeep of Building Services                         NaN   \n",
       "209               STUDENT TRANSPORT SERVICE                         NaN   \n",
       "750                                     NaN                         NaN   \n",
       "931                             Instruction  Instruction And Curriculum   \n",
       "1524             Other Community Services *                         NaN   \n",
       "\n",
       "      Position_Extra     Total  \\\n",
       "Index                            \n",
       "198              NaN  -8291.86   \n",
       "209              NaN    618.29   \n",
       "750          TEACHER  49768.82   \n",
       "931              NaN     -1.02   \n",
       "1524             NaN   2304.43   \n",
       "\n",
       "                                    Program_Description  \\\n",
       "Index                                                     \n",
       "198                                                 NaN   \n",
       "209                                PUPIL TRANSPORTATION   \n",
       "750                               Instruction - Regular   \n",
       "931    Title I, Part A Schoolwide Activities Related...   \n",
       "1524                                                NaN   \n",
       "\n",
       "                                        Fund_Description               Text_1  \n",
       "Index                                                                          \n",
       "198    Title I - Disadvantaged Children/Targeted Assi...    TITLE I CARRYOVER  \n",
       "209                                         General Fund                  NaN  \n",
       "750                               General Purpose School                  NaN  \n",
       "931                               General Operating Fund                  NaN  \n",
       "1524   Title I - Disadvantaged Children/Targeted Assi...  TITLE I PI+HOMELESS  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/mlcs_dcSchoolBudgetsTraining.csv',delimiter=\",\", thousands=',', index_col='Index')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout = pd.read_csv('data/mlcs_dcSchoolBudgetsHoldout.csv',delimiter=\",\", thousands=',', index_col='Index')\n",
    "holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1560 entries, 198 to 101861\n",
      "Data columns (total 25 columns):\n",
      "Function                  1560 non-null object\n",
      "Use                       1560 non-null object\n",
      "Sharing                   1560 non-null object\n",
      "Reporting                 1560 non-null object\n",
      "Student_Type              1560 non-null object\n",
      "Position_Type             1560 non-null object\n",
      "Object_Type               1560 non-null object\n",
      "Pre_K                     1560 non-null object\n",
      "Operating_Status          1560 non-null object\n",
      "Object_Description        1461 non-null object\n",
      "Text_2                    382 non-null object\n",
      "SubFund_Description       1183 non-null object\n",
      "Job_Title_Description     1131 non-null object\n",
      "Text_3                    296 non-null object\n",
      "Text_4                    193 non-null object\n",
      "Sub_Object_Description    364 non-null object\n",
      "Location_Description      874 non-null object\n",
      "FTE                       449 non-null float64\n",
      "Function_Description      1340 non-null object\n",
      "Facility_or_Department    252 non-null object\n",
      "Position_Extra            1026 non-null object\n",
      "Total                     1542 non-null float64\n",
      "Program_Description       1192 non-null object\n",
      "Fund_Description          819 non-null object\n",
      "Text_1                    1132 non-null object\n",
      "dtypes: float64(2), object(23)\n",
      "memory usage: 316.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type',\n",
       "       'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status',\n",
       "       'Object_Description', 'Text_2', 'SubFund_Description',\n",
       "       'Job_Title_Description', 'Text_3', 'Text_4', 'Sub_Object_Description',\n",
       "       'Location_Description', 'FTE', 'Function_Description',\n",
       "       'Facility_or_Department', 'Position_Extra', 'Total',\n",
       "       'Program_Description', 'Fund_Description', 'Text_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTE</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>449.000000</td>\n",
       "      <td>1.542000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.493532</td>\n",
       "      <td>1.446867e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.452844</td>\n",
       "      <td>7.916751e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.002369</td>\n",
       "      <td>-1.044084e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.004310</td>\n",
       "      <td>1.108125e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>7.060300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.347760e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.047222</td>\n",
       "      <td>1.367500e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FTE         Total\n",
       "count  449.000000  1.542000e+03\n",
       "mean     0.493532  1.446867e+04\n",
       "std      0.452844  7.916751e+04\n",
       "min     -0.002369 -1.044084e+06\n",
       "25%      0.004310  1.108125e+02\n",
       "50%      0.440000  7.060300e+02\n",
       "75%      1.000000  5.347760e+03\n",
       "max      1.047222  1.367500e+06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplemental *</td>\n",
       "      <td>...</td>\n",
       "      <td>Non-Certificated Salaries And Wages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Care and Upkeep of Building Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8291.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I CARRYOVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Student Transportation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Shared Services</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>OtherNon-Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12Operating</td>\n",
       "      <td>REPAIR AND MAINTENANCE SERVICES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADMIN. SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDENT TRANSPORT SERVICE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618.29</td>\n",
       "      <td>PUPIL TRANSPORTATION</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>BaseSalary/Compensation</td>\n",
       "      <td>NonPreK</td>\n",
       "      <td>PreK-12Operating</td>\n",
       "      <td>Personal Services - Teachers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>49768.82</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>...</td>\n",
       "      <td>General Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>Instruction And Curriculum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>Title I, Part A Schoolwide Activities Related...</td>\n",
       "      <td>General Operating Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>Supplies and Materials</td>\n",
       "      <td>...</td>\n",
       "      <td>Supplies And Materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other Community Services *</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2304.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Title I - Disadvantaged Children/Targeted Assi...</td>\n",
       "      <td>TITLE I PI+HOMELESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Function          Use          Sharing   Reporting  \\\n",
       "Index                                                                     \n",
       "198                  NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "209    Student Transportation     NO_LABEL  Shared Services  Non-School   \n",
       "750      Teacher Compensation  Instruction  School Reported      School   \n",
       "931                  NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "1524                 NO_LABEL     NO_LABEL         NO_LABEL    NO_LABEL   \n",
       "\n",
       "      Student_Type Position_Type              Object_Type     Pre_K  \\\n",
       "Index                                                                 \n",
       "198       NO_LABEL      NO_LABEL                 NO_LABEL  NO_LABEL   \n",
       "209       NO_LABEL      NO_LABEL    OtherNon-Compensation  NO_LABEL   \n",
       "750    Unspecified       Teacher  BaseSalary/Compensation   NonPreK   \n",
       "931       NO_LABEL      NO_LABEL                 NO_LABEL  NO_LABEL   \n",
       "1524      NO_LABEL      NO_LABEL                 NO_LABEL  NO_LABEL   \n",
       "\n",
       "       Operating_Status               Object_Description         ...           \\\n",
       "Index                                                            ...            \n",
       "198       Non-Operating                   Supplemental *         ...            \n",
       "209    PreK-12Operating  REPAIR AND MAINTENANCE SERVICES         ...            \n",
       "750    PreK-12Operating     Personal Services - Teachers         ...            \n",
       "931       Non-Operating                 General Supplies         ...            \n",
       "1524      Non-Operating           Supplies and Materials         ...            \n",
       "\n",
       "                    Sub_Object_Description Location_Description  FTE  \\\n",
       "Index                                                                  \n",
       "198    Non-Certificated Salaries And Wages                  NaN  NaN   \n",
       "209                                    NaN      ADMIN. SERVICES  NaN   \n",
       "750                                    NaN                  NaN  1.0   \n",
       "931                       General Supplies                  NaN  NaN   \n",
       "1524                Supplies And Materials                  NaN  NaN   \n",
       "\n",
       "                       Function_Description      Facility_or_Department  \\\n",
       "Index                                                                     \n",
       "198    Care and Upkeep of Building Services                         NaN   \n",
       "209               STUDENT TRANSPORT SERVICE                         NaN   \n",
       "750                                     NaN                         NaN   \n",
       "931                             Instruction  Instruction And Curriculum   \n",
       "1524             Other Community Services *                         NaN   \n",
       "\n",
       "      Position_Extra     Total  \\\n",
       "Index                            \n",
       "198              NaN  -8291.86   \n",
       "209              NaN    618.29   \n",
       "750          TEACHER  49768.82   \n",
       "931              NaN     -1.02   \n",
       "1524             NaN   2304.43   \n",
       "\n",
       "                                    Program_Description  \\\n",
       "Index                                                     \n",
       "198                                                 NaN   \n",
       "209                                PUPIL TRANSPORTATION   \n",
       "750                               Instruction - Regular   \n",
       "931    Title I, Part A Schoolwide Activities Related...   \n",
       "1524                                                NaN   \n",
       "\n",
       "                                        Fund_Description               Text_1  \n",
       "Index                                                                          \n",
       "198    Title I - Disadvantaged Children/Targeted Assi...    TITLE I CARRYOVER  \n",
       "209                                         General Fund                  NaN  \n",
       "750                               General Purpose School                  NaN  \n",
       "931                               General Operating Fund                  NaN  \n",
       "1524   Title I - Disadvantaged Children/Targeted Assi...  TITLE I PI+HOMELESS  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regular                       249\n",
       "Turnaround                     25\n",
       "Alternative                    14\n",
       "New/Closed Schl                 4\n",
       "Employee Travel                 2\n",
       "Insurance Related Expenses      1\n",
       "Charter                         1\n",
       "Name: Text_3, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n/a got taken as NaN\n",
    "df.Text_3.value_counts()\n",
    "\n",
    "# df.FTE.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              FTE         Total\n",
      "count  449.000000  1.542000e+03\n",
      "mean     0.493532  1.446867e+04\n",
      "std      0.452844  7.916751e+04\n",
      "min     -0.002369 -1.044084e+06\n",
      "25%      0.004310  1.108125e+02\n",
      "50%      0.440000  7.060300e+02\n",
      "75%      1.000000  5.347760e+03\n",
      "max      1.047222  1.367500e+06\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAGMCAYAAACs1Gc1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABTI+gAAKZG0AEATI2gAwCY2v8DYG8QbJJzBUMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(df['FTE'].dropna())\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The high variance in expenditures makes sense (some purchases are cheap some are expensive). Also, it looks like the FTE column is bimodal. That is, there are some part-time and some full-time employees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Binary indicator' representation\n",
    "`  In [4]: dummies = pd.get_dummies(sample_df[['label']], prefix_sep='_')\n",
    "  In [5]: dummies.head(2)\n",
    "Out[5]:\n",
    "   label_a  label_b\n",
    "0  1        0 \n",
    "1  0        1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! That's a lot of (slow) object types. Let's do some type conversion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = ['Function',\n",
    " 'Use',\n",
    " 'Sharing',\n",
    " 'Reporting',\n",
    " 'Student_Type',\n",
    " 'Position_Type',\n",
    " 'Object_Type',\n",
    " 'Pre_K',\n",
    " 'Operating_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function            object\n",
       "Use                 object\n",
       "Sharing             object\n",
       "Reporting           object\n",
       "Student_Type        object\n",
       "Position_Type       object\n",
       "Object_Type         object\n",
       "Pre_K               object\n",
       "Operating_Status    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[LABELS].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that every label is encoded as an object datatype. Because category datatypes are much more efficient your task is to convert the labels to category types using the .astype() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "df[LABELS] = df[LABELS].apply(categorize_label, axis=0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAG4CAYAAADCNHkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = df[LABELS].apply(pd.Series.nunique)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot(kind='bar')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log loss (binary classification):\n",
    "\n",
    "$$ logloss = - \\frac{1}{N}\\sum_{i=1}^N(y_ilog(p_i) + (1 - y_i)log(1-p_i))$$\n",
    "\n",
    "Aim is to minimize logloss\n",
    "Clipping is used to make sure that the log loss stays a real number\n",
    "log loss is good because it rewards you for being uncertain, rather than being certain but wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    \"\"\" Computes the logarithmic loss between predicted and\n",
    "        actual when these are 1D arrays.\n",
    "         :param predicted: The predicted probabilities as floats between 0-1\n",
    "         :param actual: The actual binary labels. Either 0 or 1.\n",
    "         :param eps (optional): log(0) is inf, so we need to offset our\n",
    "    \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1 - eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted)\n",
    "                        + (1 - actual)* np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_log_loss(predicted=0.9, actual=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_log_loss(predicted=0.5, actual=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16251892949777494\n",
      "4.605170185988091\n",
      "0.7133498878774648\n"
     ]
    }
   ],
   "source": [
    "print(compute_log_loss(predicted=0.85, actual=1))\n",
    "print(compute_log_loss(predicted=0.99, actual=0))\n",
    "print(compute_log_loss(predicted=0.51, actual=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_labels = np.array([ 1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])\n",
    "correct_confident = np.array([ 0.95,  0.95,  0.95,  0.95,  0.95,  0.05,  0.05,  0.05,  0.05,  0.05])\n",
    "correct_not_confident = np.array([ 0.65,  0.65,  0.65,  0.65,  0.65,  0.35,  0.35,  0.35,  0.35,  0.35])\n",
    "wrong_not_confident = np.array([ 0.35,  0.35,  0.35,  0.35,  0.35,  0.65,  0.65,  0.65,  0.65,  0.65])\n",
    "wrong_confident = np.array([ 0.05,  0.05,  0.05,  0.05,  0.05,  0.95,  0.95,  0.95,  0.95,  0.95])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss, correct and confident: 0.05129329438755058\n",
      "Log loss, correct and not confident: 0.4307829160924542\n",
      "Log loss, wrong and not confident: 1.049822124498678\n",
      "Log loss, wrong and confident: 2.9957322735539904\n",
      "Log loss, actual labels: 9.99200722162646e-15\n"
     ]
    }
   ],
   "source": [
    "# Compute and print log loss for 1st case\n",
    "correct_confident = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading multicategory util for spliting test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multilabel import multilabel_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1040 entries, 198 to 101861\n",
      "Data columns (total 2 columns):\n",
      "FTE      1040 non-null float64\n",
      "Total    1040 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 24.4 KB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 520 entries, 209 to 448628\n",
      "Data columns (total 2 columns):\n",
      "FTE      520 non-null float64\n",
      "Total    520 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 12.2 KB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1040 entries, 198 to 101861\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 113.8 KB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 520 entries, 209 to 448628\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 56.9 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisonkline/Code/Springtime/Reference/multilabel.py:30: UserWarning: Size less than number of columns * min_count, returning 520 items instead of 312.0.\n",
      "  warn(msg.format(y.shape[1] * min_count, size))\n"
     ]
    }
   ],
   "source": [
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only, label_dummies, size=0.2, seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very first crappy model - to get up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 237 to 142060\n",
      "Data columns (total 16 columns):\n",
      "Object_Description        1918 non-null object\n",
      "Program_Description       1798 non-null object\n",
      "SubFund_Description       664 non-null object\n",
      "Job_Title_Description     1303 non-null object\n",
      "Facility_or_Department    133 non-null object\n",
      "Sub_Object_Description    1317 non-null object\n",
      "Location_Description      1515 non-null object\n",
      "FTE                       782 non-null float64\n",
      "Function_Description      1851 non-null object\n",
      "Position_Extra            594 non-null object\n",
      "Text_4                    137 non-null object\n",
      "Total                     1974 non-null float64\n",
      "Text_2                    198 non-null object\n",
      "Text_3                    216 non-null object\n",
      "Fund_Description          1559 non-null object\n",
      "Text_1                    627 non-null object\n",
      "dtypes: float64(2), object(14)\n",
      "memory usage: 265.6+ KB\n"
     ]
    }
   ],
   "source": [
    "holdout.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit it to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Load the holdout data: holdout - done above\n",
    "# holdout = pd.read_csv('HoldoutData.csv', index_col=0)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function__Aides Compensation</th>\n",
       "      <th>Function__Career &amp; Academic Counseling</th>\n",
       "      <th>Function__Communications</th>\n",
       "      <th>Function__Curriculum Development</th>\n",
       "      <th>Function__Data Processing &amp; Information Services</th>\n",
       "      <th>Function__Development &amp; Fundraising</th>\n",
       "      <th>Function__Enrichment</th>\n",
       "      <th>Function__Extended Time &amp; Tutoring</th>\n",
       "      <th>Function__Facilities &amp; Maintenance</th>\n",
       "      <th>Function__Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Object_Type__Rent/Utilities</th>\n",
       "      <th>Object_Type__SubstituteCompensation</th>\n",
       "      <th>Object_Type__Supplies/Materials</th>\n",
       "      <th>Object_Type__Travel&amp;Conferences</th>\n",
       "      <th>Pre_K__NO_LABEL</th>\n",
       "      <th>Pre_K__NonPreK</th>\n",
       "      <th>Pre_K__PreK</th>\n",
       "      <th>Operating_Status__Non-Operating</th>\n",
       "      <th>Operating_Status__Operating</th>\n",
       "      <th>Operating_Status__PreK-12Operating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.078738</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>0.023473</td>\n",
       "      <td>0.037825</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.045953</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.026714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.106849</td>\n",
       "      <td>0.144711</td>\n",
       "      <td>0.031489</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.471727</td>\n",
       "      <td>0.093675</td>\n",
       "      <td>0.128281</td>\n",
       "      <td>0.031392</td>\n",
       "      <td>0.856131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>0.013398</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.035841</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.040454</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024547</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.109979</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>0.776878</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.036248</td>\n",
       "      <td>0.079058</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.907521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>0.078753</td>\n",
       "      <td>0.051596</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0.037830</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>0.112320</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.106880</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>0.031493</td>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.471737</td>\n",
       "      <td>0.093697</td>\n",
       "      <td>0.128314</td>\n",
       "      <td>0.031386</td>\n",
       "      <td>0.856105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0.077957</td>\n",
       "      <td>0.051315</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>0.030215</td>\n",
       "      <td>0.045631</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>0.111437</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039762</td>\n",
       "      <td>0.105286</td>\n",
       "      <td>0.143345</td>\n",
       "      <td>0.031285</td>\n",
       "      <td>0.500813</td>\n",
       "      <td>0.471256</td>\n",
       "      <td>0.092575</td>\n",
       "      <td>0.126583</td>\n",
       "      <td>0.031695</td>\n",
       "      <td>0.857452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>0.024601</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.013390</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.035772</td>\n",
       "      <td>0.019302</td>\n",
       "      <td>0.040361</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024548</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.109682</td>\n",
       "      <td>0.039869</td>\n",
       "      <td>0.777027</td>\n",
       "      <td>0.184322</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>0.078753</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>0.907769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Function__Aides Compensation  Function__Career & Academic Counseling  \\\n",
       "Index                                                                         \n",
       "237                        0.078738                                0.051591   \n",
       "466                        0.024672                                0.012990   \n",
       "784                        0.078753                                0.051596   \n",
       "1786                       0.077957                                0.051315   \n",
       "2643                       0.024601                                0.012970   \n",
       "\n",
       "       Function__Communications  Function__Curriculum Development  \\\n",
       "Index                                                               \n",
       "237                    0.023473                          0.037825   \n",
       "466                    0.008821                          0.037150   \n",
       "784                    0.023477                          0.037830   \n",
       "1786                   0.023276                          0.037560   \n",
       "2643                   0.008800                          0.037079   \n",
       "\n",
       "       Function__Data Processing & Information Services  \\\n",
       "Index                                                     \n",
       "237                                            0.036767   \n",
       "466                                            0.013398   \n",
       "784                                            0.036769   \n",
       "1786                                           0.036692   \n",
       "2643                                           0.013390   \n",
       "\n",
       "       Function__Development & Fundraising  Function__Enrichment  \\\n",
       "Index                                                              \n",
       "237                               0.030503              0.045953   \n",
       "466                               0.004973              0.035841   \n",
       "784                               0.030509              0.045959   \n",
       "1786                              0.030215              0.045631   \n",
       "2643                              0.004960              0.035772   \n",
       "\n",
       "       Function__Extended Time & Tutoring  Function__Facilities & Maintenance  \\\n",
       "Index                                                                           \n",
       "237                              0.050615                            0.112303   \n",
       "466                              0.019366                            0.040454   \n",
       "784                              0.050627                            0.112320   \n",
       "1786                             0.050024                            0.111437   \n",
       "2643                             0.019302                            0.040361   \n",
       "\n",
       "       Function__Facilities Planning                 ...                  \\\n",
       "Index                                                ...                   \n",
       "237                         0.026714                 ...                   \n",
       "466                         0.004951                 ...                   \n",
       "784                         0.026720                 ...                   \n",
       "1786                        0.026451                 ...                   \n",
       "2643                        0.004938                 ...                   \n",
       "\n",
       "       Object_Type__Rent/Utilities  Object_Type__SubstituteCompensation  \\\n",
       "Index                                                                     \n",
       "237                       0.039759                             0.106849   \n",
       "466                       0.024547                             0.020690   \n",
       "784                       0.039759                             0.106880   \n",
       "1786                      0.039762                             0.105286   \n",
       "2643                      0.024548                             0.020599   \n",
       "\n",
       "       Object_Type__Supplies/Materials  Object_Type__Travel&Conferences  \\\n",
       "Index                                                                     \n",
       "237                           0.144711                         0.031489   \n",
       "466                           0.109979                         0.039939   \n",
       "784                           0.144737                         0.031493   \n",
       "1786                          0.143345                         0.031285   \n",
       "2643                          0.109682                         0.039869   \n",
       "\n",
       "       Pre_K__NO_LABEL  Pre_K__NonPreK  Pre_K__PreK  \\\n",
       "Index                                                 \n",
       "237           0.500027        0.471727     0.093675   \n",
       "466           0.776878        0.184400     0.036248   \n",
       "784           0.500012        0.471737     0.093697   \n",
       "1786          0.500813        0.471256     0.092575   \n",
       "2643          0.777027        0.184322     0.036123   \n",
       "\n",
       "       Operating_Status__Non-Operating  Operating_Status__Operating  \\\n",
       "Index                                                                 \n",
       "237                           0.128281                     0.031392   \n",
       "466                           0.079058                     0.011526   \n",
       "784                           0.128314                     0.031386   \n",
       "1786                          0.126583                     0.031695   \n",
       "2643                          0.078753                     0.011557   \n",
       "\n",
       "       Operating_Status__PreK-12Operating  \n",
       "Index                                      \n",
       "237                              0.856131  \n",
       "466                              0.907521  \n",
       "784                              0.856105  \n",
       "1786                             0.857452  \n",
       "2643                             0.907769  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function_Aides Compensation</th>\n",
       "      <th>Function_Career &amp; Academic Counseling</th>\n",
       "      <th>Function_Communications</th>\n",
       "      <th>Function_Curriculum Development</th>\n",
       "      <th>Function_Data Processing &amp; Information Services</th>\n",
       "      <th>Function_Development &amp; Fundraising</th>\n",
       "      <th>Function_Enrichment</th>\n",
       "      <th>Function_Extended Time &amp; Tutoring</th>\n",
       "      <th>Function_Facilities &amp; Maintenance</th>\n",
       "      <th>Function_Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Object_Type_Rent/Utilities</th>\n",
       "      <th>Object_Type_SubstituteCompensation</th>\n",
       "      <th>Object_Type_Supplies/Materials</th>\n",
       "      <th>Object_Type_Travel&amp;Conferences</th>\n",
       "      <th>Pre_K_NO_LABEL</th>\n",
       "      <th>Pre_K_NonPreK</th>\n",
       "      <th>Pre_K_PreK</th>\n",
       "      <th>Operating_Status_Non-Operating</th>\n",
       "      <th>Operating_Status_Operating</th>\n",
       "      <th>Operating_Status_PreK-12Operating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.078738</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>0.023473</td>\n",
       "      <td>0.037825</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.045953</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.026714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.106849</td>\n",
       "      <td>0.144711</td>\n",
       "      <td>0.031489</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.471727</td>\n",
       "      <td>0.093675</td>\n",
       "      <td>0.128281</td>\n",
       "      <td>0.031392</td>\n",
       "      <td>0.856131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>0.013398</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.035841</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.040454</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024547</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.109979</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>0.776878</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.036248</td>\n",
       "      <td>0.079058</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.907521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>0.078753</td>\n",
       "      <td>0.051596</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0.037830</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>0.045959</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>0.112320</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.106880</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>0.031493</td>\n",
       "      <td>0.500012</td>\n",
       "      <td>0.471737</td>\n",
       "      <td>0.093697</td>\n",
       "      <td>0.128314</td>\n",
       "      <td>0.031386</td>\n",
       "      <td>0.856105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0.077957</td>\n",
       "      <td>0.051315</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>0.030215</td>\n",
       "      <td>0.045631</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>0.111437</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039762</td>\n",
       "      <td>0.105286</td>\n",
       "      <td>0.143345</td>\n",
       "      <td>0.031285</td>\n",
       "      <td>0.500813</td>\n",
       "      <td>0.471256</td>\n",
       "      <td>0.092575</td>\n",
       "      <td>0.126583</td>\n",
       "      <td>0.031695</td>\n",
       "      <td>0.857452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>0.024601</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.037079</td>\n",
       "      <td>0.013390</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.035772</td>\n",
       "      <td>0.019302</td>\n",
       "      <td>0.040361</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024548</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.109682</td>\n",
       "      <td>0.039869</td>\n",
       "      <td>0.777027</td>\n",
       "      <td>0.184322</td>\n",
       "      <td>0.036123</td>\n",
       "      <td>0.078753</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>0.907769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Function_Aides Compensation  Function_Career & Academic Counseling  \\\n",
       "Index                                                                       \n",
       "237                       0.078738                               0.051591   \n",
       "466                       0.024672                               0.012990   \n",
       "784                       0.078753                               0.051596   \n",
       "1786                      0.077957                               0.051315   \n",
       "2643                      0.024601                               0.012970   \n",
       "\n",
       "       Function_Communications  Function_Curriculum Development  \\\n",
       "Index                                                             \n",
       "237                   0.023473                         0.037825   \n",
       "466                   0.008821                         0.037150   \n",
       "784                   0.023477                         0.037830   \n",
       "1786                  0.023276                         0.037560   \n",
       "2643                  0.008800                         0.037079   \n",
       "\n",
       "       Function_Data Processing & Information Services  \\\n",
       "Index                                                    \n",
       "237                                           0.036767   \n",
       "466                                           0.013398   \n",
       "784                                           0.036769   \n",
       "1786                                          0.036692   \n",
       "2643                                          0.013390   \n",
       "\n",
       "       Function_Development & Fundraising  Function_Enrichment  \\\n",
       "Index                                                            \n",
       "237                              0.030503             0.045953   \n",
       "466                              0.004973             0.035841   \n",
       "784                              0.030509             0.045959   \n",
       "1786                             0.030215             0.045631   \n",
       "2643                             0.004960             0.035772   \n",
       "\n",
       "       Function_Extended Time & Tutoring  Function_Facilities & Maintenance  \\\n",
       "Index                                                                         \n",
       "237                             0.050615                           0.112303   \n",
       "466                             0.019366                           0.040454   \n",
       "784                             0.050627                           0.112320   \n",
       "1786                            0.050024                           0.111437   \n",
       "2643                            0.019302                           0.040361   \n",
       "\n",
       "       Function_Facilities Planning                ...                  \\\n",
       "Index                                              ...                   \n",
       "237                        0.026714                ...                   \n",
       "466                        0.004951                ...                   \n",
       "784                        0.026720                ...                   \n",
       "1786                       0.026451                ...                   \n",
       "2643                       0.004938                ...                   \n",
       "\n",
       "       Object_Type_Rent/Utilities  Object_Type_SubstituteCompensation  \\\n",
       "Index                                                                   \n",
       "237                      0.039759                            0.106849   \n",
       "466                      0.024547                            0.020690   \n",
       "784                      0.039759                            0.106880   \n",
       "1786                     0.039762                            0.105286   \n",
       "2643                     0.024548                            0.020599   \n",
       "\n",
       "       Object_Type_Supplies/Materials  Object_Type_Travel&Conferences  \\\n",
       "Index                                                                   \n",
       "237                          0.144711                        0.031489   \n",
       "466                          0.109979                        0.039939   \n",
       "784                          0.144737                        0.031493   \n",
       "1786                         0.143345                        0.031285   \n",
       "2643                         0.109682                        0.039869   \n",
       "\n",
       "       Pre_K_NO_LABEL  Pre_K_NonPreK  Pre_K_PreK  \\\n",
       "Index                                              \n",
       "237          0.500027       0.471727    0.093675   \n",
       "466          0.776878       0.184400    0.036248   \n",
       "784          0.500012       0.471737    0.093697   \n",
       "1786         0.500813       0.471256    0.092575   \n",
       "2643         0.777027       0.184322    0.036123   \n",
       "\n",
       "       Operating_Status_Non-Operating  Operating_Status_Operating  \\\n",
       "Index                                                               \n",
       "237                          0.128281                    0.031392   \n",
       "466                          0.079058                    0.011526   \n",
       "784                          0.128314                    0.031386   \n",
       "1786                         0.126583                    0.031695   \n",
       "2643                         0.078753                    0.011557   \n",
       "\n",
       "       Operating_Status_PreK-12Operating  \n",
       "Index                                     \n",
       "237                             0.856131  \n",
       "466                             0.907521  \n",
       "784                             0.856105  \n",
       "1786                            0.857452  \n",
       "2643                            0.907769  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model, trained with numeric data only, yields logloss score: 1.9067227623381413\n"
     ]
    }
   ],
   "source": [
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df1 = pd.DataFrame(columns=pd.get_dummies(df[LABELS],prefix_sep='__').columns,\n",
    "                             index=holdout.index,data=predictions)\n",
    "\n",
    "display(prediction_df1.head())\n",
    "\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS]).columns,\n",
    "                             index=holdout.index,data=predictions)\n",
    "display(prediction_df.head())\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('data/predictions.csv')\n",
    "\n",
    "# Submit the predictions for scoring: score\n",
    "#score = score_submission(pred_path='data/predictions.csv')\n",
    "score = 1.9067227623381413   #From scoreing submission script/process\n",
    "\n",
    "# Print score\n",
    "print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a bag-of-words in scikit-learn\n",
    "In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.\n",
    "\n",
    "You will focus on one feature only, the Position_Extra column, which describes any additional information not captured by the Position_Type label.\n",
    "\n",
    "For example, in the Shell you can check out the budget item in row 8960 of the data using df.loc[8960]. Looking at the output reveals that this Object_Description is overtime pay. For who? The Position Type is merely \"other\", but the Position Extra elaborates: \"BUS DRIVER\". Explore the column further to see more instances. It has a lot of NaN values.\n",
    "\n",
    "Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.\n",
    "\n",
    "For comparison purposes, the first 15 tokens of vec_basic, which splits df.Position_Extra into tokens when it encounters only whitespace characters, have been printed along with the length of the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function                                         Student Transportation\n",
       "Use                                                                 O&M\n",
       "Sharing                                                 Shared Services\n",
       "Reporting                                                    Non-School\n",
       "Student_Type                                                Unspecified\n",
       "Position_Type                                                     Other\n",
       "Object_Type                                   OtherCompensation/Stipend\n",
       "Pre_K                                                           NonPreK\n",
       "Operating_Status                                       PreK-12Operating\n",
       "Object_Description        Extra Duty Pay/Overtime For Support Personnel\n",
       "Text_2                                                              NaN\n",
       "SubFund_Description                                          Operations\n",
       "Job_Title_Description                     TRANSPORTATION,BUS DR., RADIO\n",
       "Text_3                                                              NaN\n",
       "Text_4                                     transportation - Second Runs\n",
       "Sub_Object_Description    Extra Duty Pay/Overtime For Support Personnel\n",
       "Location_Description                                        Unallocated\n",
       "FTE                                                                 NaN\n",
       "Function_Description                                     Transportation\n",
       "Facility_or_Department                        Transportation Department\n",
       "Position_Extra                                               BUS DRIVER\n",
       "Total                                                           1752.45\n",
       "Program_Description                                       Undistributed\n",
       "Fund_Description                                 General Operating Fund\n",
       "Text_1                                                    EXTENDED DAYS\n",
       "Name: 8960, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2,:]\n",
    "df.loc[8960]\n",
    "# df.loc[df['Unnamed: 0'] == 8960]  #when index was an un-named first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 110 tokens in Position_Extra if we split on non-alpha numeric\n",
      "['1st', '2nd', '3rd', 'a', 'ab', 'additional', 'adm', 'administrative', 'and', 'any', 'assessment', 'assistant', 'asst', 'athletic', 'avg']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Official output:\n",
    "\n",
    "    There are 123 tokens in Position_Extra if we split on non-alpha numeric\n",
    "    ['1st', '2nd', '3rd', 'a', 'ab', 'additional', 'adm', 'administrative', 'and', 'any', 'art', 'assessment', 'assistant', 'asst', 'athletic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining text columns for tokenization\n",
    "In order to get a bag-of-words representation for all of the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.\n",
    "\n",
    "In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. CountVectorizer expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.\n",
    "\n",
    "In this exercise, you'll complete the function definition combine_text_columns(). When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1370 tokens in the dataset\n",
      "There are 1077 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Official output:\n",
    "\n",
    "    There are 1405 tokens in the dataset\n",
    "    There are 1117 alpha-numeric tokens in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      "numeric         1000 non-null float64\n",
      "text            790 non-null object\n",
      "with_missing    822 non-null float64\n",
      "label           1000 non-null object\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 39.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# toy data for practing pipelines\n",
    "sample_df = pd.read_csv('data/mlcs_dcSchoolBudgetsSampleDF.csv',delimiter=\",\", index_col='index')\n",
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - numeric, no nans:  0.62\n"
     ]
    }
   ],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import other necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Split and select numeric data only, no nans \n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - numeric, no nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing numeric features\n",
    "What would have happened if you had included the with 'with_missing' column in the last exercise? Without imputing missing values, the pipeline would not be happy (try it and see). So, in this exercise you'll improve your pipeline a bit by using the Imputer() imputation transformer from scikit-learn to fill in missing values in your sample data.\n",
    "\n",
    "By default, the imputer transformer replaces NaNs with the mean value of the column. That's a good enough imputation strategy for the sample data, so you won't need to pass anything extra to the imputer.\n",
    "\n",
    "After importing the transformer, you will edit the steps list used in the previous exercise by inserting a (name, transform) tuple. Recall that steps are processed sequentially, so make sure the new tuple encoding your preprocessing step is put in the right place.\n",
    "\n",
    "The sample_df is in the workspace, in case you'd like to take another look. Make sure to select both numeric columns- in the previous exercise we couldn't use with_missing because we had no preprocessing step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - all numeric, incl nans:  0.636\n"
     ]
    }
   ],
   "source": [
    "# Import the Imputer object\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Create training and test sets using only numeric data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Insantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('imp', Imputer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all numeric, incl nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text features\n",
    "Here, you'll perform a similar preprocessing pipeline step, only this time you'll use the text column from the sample data.\n",
    "\n",
    "To preprocess the text, you'll turn to CountVectorizer() to generate a bag-of-words representation of the data, as in Chapter 2. Using the default arguments, add a (step, transform) tuple to the steps list in your pipeline.\n",
    "\n",
    "Make sure you select only the text column for splitting your training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - just text data:  0.808\n"
     ]
    }
   ],
   "source": [
    "# Split out only the text data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df['text'].fillna(' '),\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('vec', CountVectorizer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - just text data: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple types of processing: FunctionTransformer\n",
    "The next two exercises will introduce new topics you'll need to make your pipeline truly excel.\n",
    "\n",
    "Any step in the pipeline must be an object that implements the fit and transform methods. The FunctionTransformer creates an object with these methods out of any Python function that you pass to it. We'll use it to help select subsets of data in a way that plays nicely with pipelines.\n",
    "\n",
    "You are working with numeric data that needs imputation, and text data that needs to be converted into a bag-of-words. You'll create functions that separate the text from the numeric variables and see how the .fit() and .transform() methods work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data\n",
      "index\n",
      "0           \n",
      "1        foo\n",
      "2    foo bar\n",
      "3           \n",
      "4    foo bar\n",
      "Name: text, dtype: object\n",
      "\n",
      "Numeric Data\n",
      "         numeric  with_missing\n",
      "index                         \n",
      "0     -10.856306      4.433240\n",
      "1       9.973454      4.310229\n",
      "2       2.829785      2.469828\n",
      "3     -15.062947      2.852981\n",
      "4      -5.786003      1.826475\n"
     ]
    }
   ],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'].fillna(' '), validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# Print head to check results\n",
    "print('Text Data')\n",
    "print(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple types of processing: FeatureUnion\n",
    "Now that you can separate text and numeric data in your pipeline, you're ready to perform separate steps on each by nesting pipelines and using FeatureUnion().\n",
    "\n",
    "These tools will allow you to streamline all preprocessing steps for your model, even when multiple datatypes are involved. Here, for example, you don't want to impute our text data, and you don't want to create a bag-of-words with our numeric data. Instead, you want to deal with these separately and then join the results together using FeatureUnion().\n",
    "\n",
    "In the end, you'll still have only two high-level steps in your pipeline: preprocessing and model instantiation. The difference is that the first preprocessing step actually consists of a pipeline for numeric data and a pipeline for text data. The results of those pipelines are joined using FeatureUnion()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - all data:  0.928\n"
     ]
    }
   ],
   "source": [
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sample_df[['numeric', 'with_missing', 'text']],\n",
    "               pd.get_dummies(sample_df['label']), random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on sample data - all data:  0.928\n"
     ]
    }
   ],
   "source": [
    "# alternative way to structure the same pipeline\n",
    "numeric_pipeline = Pipeline([\n",
    "                        ('selector', get_numeric_data),\n",
    "                        ('imputer', Imputer())\n",
    "                    ])\n",
    "text_pipeline = Pipeline([\n",
    "                        ('selector', get_text_data),\n",
    "                        ('vectorizer', CountVectorizer())\n",
    "                    ])\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion([\n",
    "            ('numeric', numeric_pipeline),\n",
    "            ('text', text_pipeline)\n",
    "        ])),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression())) \n",
    "    ])\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FunctionTransformer on the main dataset\n",
    "In this exercise you're going to use FunctionTransformer on the primary budget data.\n",
    "\n",
    "Recall the combine_text_columns function to select and properly format text data for tokenization - we'll need that.\n",
    "\n",
    "Concerning the numeric data, you can use NUMERIC_COLUMNS, to help design a subset-selecting lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisonkline/Code/Springtime/Reference/multilabel.py:30: UserWarning: Size less than number of columns * min_count, returning 520 items instead of 312.0.\n",
      "  warn(msg.format(y.shape[1] * min_count, size))\n"
     ]
    }
   ],
   "source": [
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels, 0.2, seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a model to the pipeline\n",
    "You're about to take everything you've learned so far and implement it in a Pipeline that works with the real, Driven Data budget line item data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.20576923076923076\n"
     ]
    }
   ],
   "source": [
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a different class of model\n",
    "One of the great strengths of pipelines is how easy they make the process of testing different models.\n",
    "\n",
    "We've been using the model step ('clf', OneVsRestClassifier(LogisticRegression())) \n",
    "\n",
    "now lets swap out the logistic-regression model and replace it with a random forest classifier, which uses the statistics of an ensemble of decision trees to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.28076923076923077\n"
     ]
    }
   ],
   "source": [
    "# Import random forest classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on budget dataset:  0.3211538461538462\n"
     ]
    }
   ],
   "source": [
    "# Add model step to pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators=15))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding what's a word\n",
    "Lets look a little deeper into how the text features will be processed.\n",
    "\n",
    "Use CountVectorizer on the training data X_train to see the effect of tokenization on punctuation.\n",
    "\n",
    "Since CountVectorizer expects a vector, you use combine_text_columns before fitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', '1st', '2nd', '4th', '5th', '70h', '8', 'a', 'ab', 'acad']\n"
     ]
    }
   ],
   "source": [
    "# Create the text vector\n",
    "text_vector = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate the CountVectorizer: text_features\n",
    "text_features = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit text_features to the text vector\n",
    "text_features.fit(text_vector)\n",
    "\n",
    "# Print the first 10 tokens\n",
    "print(text_features.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range in scikit-learn\n",
    "In this exercise you'll insert a CountVectorizer instance into your pipeline for the main dataset, and compute multiple n-gram features to be used in the model.\n",
    "\n",
    "In order to look for ngram relationships at multiple scales, you will use the ngram_range parameter.\n",
    "\n",
    "Special functions: You'll notice a couple of new steps provided in the pipeline in this and many of the remaining exercises. Specifically, the dim_red step following the vectorizer step , and the scale step preceeding the clf (classification) step.\n",
    "\n",
    "These have been added in order to account for the fact that you're using a reduced-size sample of the full dataset in this course. To make sure the models perform as the expert competition winner intended, we have to apply a dimensionality reduction technique, which is what the dim_red step does, and we have to scale the features to lie between -1 and 1, which is what the scale step does.\n",
    "\n",
    "The dim_red step uses a scikit-learn function called SelectKBest(), applying something called the chi-squared test to select the K \"best\" features. The scale step uses a scikit-learn function called MaxAbsScaler() in order to squash the relevant features into the interval -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import other preprocessing modules\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Select 300 best features\n",
    "chi_k = 300\n",
    "\n",
    "# Import functional utilities\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Perform preprocessing\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement interaction modeling in scikit-learn\n",
    "It's time to add interaction features to your model. The PolynomialFeatures object in scikit-learn does just that, but here you're going to use a custom interaction object, SparseInteractions. Interaction terms are a statistical tool that lets your model express what happens if two features appear together in the same row.\n",
    "\n",
    "SparseInteractions does the same thing as PolynomialFeatures, but it uses sparse matrices to do so. You can get the code for SparseInteractions at this [GitHub Gist](https://github.com/drivendataorg/box-plots-sklearn/blob/master/src/features/SparseInteractions.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class SparseInteractions(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, degree=2, feature_name_separator=\"_\"):\n",
    "        self.degree = degree\n",
    "        self.feature_name_separator = feature_name_separator\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not sparse.isspmatrix_csc(X):\n",
    "            X = sparse.csc_matrix(X)\n",
    "\n",
    "        if hasattr(X, \"columns\"):\n",
    "            self.orig_col_names = X.columns\n",
    "        else:\n",
    "            self.orig_col_names = np.array([str(i) for i in range(X.shape[1])])\n",
    "\n",
    "        spi = self._create_sparse_interactions(X)\n",
    "        return spi\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names\n",
    "\n",
    "    def _create_sparse_interactions(self, X):\n",
    "        out_mat = []\n",
    "        self.feature_names = self.orig_col_names.tolist()\n",
    "\n",
    "        for sub_degree in range(2, self.degree + 1):\n",
    "            for col_ixs in combinations(range(X.shape[1]), sub_degree):\n",
    "                # add name for new column\n",
    "                name = self.feature_name_separator.join(self.orig_col_names[list(col_ixs)])\n",
    "                self.feature_names.append(name)\n",
    "\n",
    "                # get column multiplications value\n",
    "                out = X[:, col_ixs[0]]\n",
    "                for j in col_ixs[1:]:\n",
    "                    out = out.multiply(X[:, j])\n",
    "\n",
    "                out_mat.append(out)\n",
    "\n",
    "        return sparse.hstack([X] + out_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PolynomialFeatures and SparseInteractions both take the argument degree, which tells them what polynomial degree of interactions to compute.\n",
    "\n",
    "You're going to consider interaction terms of degree=2 in your pipeline. You will insert these steps after the preprocessing steps you've built out so far, but before the classifier steps.\n",
    "\n",
    "Pipelines with interaction terms take a while to train (since you're making n features into n-squared features!), so as long as you set it up right, we'll do the heavy lifting and tell you what your score is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1, 2))),  \n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisonkline/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric_features', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x10ecb0ea0>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprec...=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-5308b916d296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_multi_log_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlog_loss_scorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_multi_log_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.scorer import make_scorer\n",
    "from models.metrics import multi_multi_log_loss\n",
    "\n",
    "log_loss_scorer = make_scorer(multi_multi_log_loss)\n",
    "# a version of multi_multi_log_loss is here:\n",
    "# https://github.com/drivendataorg/metrics/blob/master/metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)\n",
    "# print the score of our trained pipeline on our test set\n",
    "print(\"Logloss score of trained pipeline: \", log_loss_scorer(pl, X_test, y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not sure how to add up the log loss - due to training delays the program just gave to answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log loss score: 1.2256. Nice improvement from 1.2681!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the hashing trick in scikit-learn\n",
    "In this exercise you will check out the scikit-learn implementation of HashingVectorizer before adding it to your pipeline later.\n",
    "\n",
    "As you saw in the video, HashingVectorizer acts just like CountVectorizer in that it can accept token_pattern and ngram_range parameters. The important difference is that it creates hash values from the text, so that we get all the computational advantages of hashing!\n",
    "\n",
    "This exercise was implemented on a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.164399\n",
      "1 -0.493197\n",
      "2 -0.328798\n",
      "3  0.164399\n",
      "4  0.164399\n"
     ]
    }
   ],
   "source": [
    "# Import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Get text data: text_data\n",
    "text_data = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)' \n",
    "\n",
    "# Instantiate the HashingVectorizer: hashing_vec\n",
    "hashing_vec = HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit and transform the Hashing Vectorizer\n",
    "hashed_text = hashing_vec.fit_transform(text_data)\n",
    "\n",
    "# Create DataFrame and print the head\n",
    "hashed_df = pd.DataFrame(hashed_text.data)\n",
    "print(hashed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the winning model\n",
    "It's time to build the model that won DrivenData's competition.\n",
    "\n",
    "You've constructed a robust, powerful pipeline capable of processing training and testing data. Now that you understand the data and know all of the tools you need, you can essentially solve the whole problem in a relatively small number of lines of code.\n",
    "\n",
    "All you need to do is add the HashingVectorizer step to the pipeline to replace the CountVectorizer step.\n",
    "\n",
    "The parameters non_negative=True, norm=None, and binary=False make the HashingVectorizer perform similarly to the default settings on the CountVectorizer so you can just replace one with the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the winning model pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                     non_negative=True, norm=None, binary=False,\n",
    "                                                     ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! Log loss: 1.2258. Looks like the performance is about the same, but this is expected since the HashingVectorizer should work the same as the CountVectorizer. Try this pipeline out on the whole dataset on your local machine to see its full power!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What tactics got the winner the best score?\n",
    "Now you've implemented the winning model from start to finish. If you want to use this model locally, this [Jupyter notebook](https://github.com/datacamp/course-resources-ml-with-experts-budgets/blob/master/notebooks/1.0-full-model.ipynb) contains all the code you've worked so hard on. You can now take that code and build on it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
